{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KdYz_FghOiuQWVIG9hn1PwVC84VhxMQu","timestamp":1711805054926}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hhdpwdE1z5aU"},"outputs":[],"source":["import numpy as np\n","# from submit import my_map\n","# from submit import my_fit\n","import time as tm"]},{"cell_type":"code","source":["# SUBMIT.PY FILE #\n","\n","import numpy as np\n","import sklearn\n","from scipy.linalg import khatri_rao\n","from sklearn.linear_model import LogisticRegression\n","\n","\n","def my_fit( X_train, y_train ):\n","\tfeatures = my_map(X_train)\n","\tlabels = y_train\n","\tmodel = LogisticRegression(C = 100, max_iter = 500, penalty = 'l2', solver = 'lbfgs', tol = 0.01)\n","\tmodel.fit(features, labels)\n","\tw = model.coef_.flatten()\n","\tb = model.intercept_[0]\n","\treturn w, b\n","\n","def my_map( X ):\n","\tX = np.flip(np.cumprod(np.flip(2 * X - 1, axis = 1), axis = 1), axis = 1)\n","\tX = np.hstack((X, np.ones((X.shape[0], 1))))\n","\t# X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)\n","\tnum_columns = X.shape[1]\n","\tfeat = np.empty((X.shape[0], num_columns * (num_columns - 1) // 2))\n","\tidx = 0\n","\tfor i in range(num_columns):\n","\t\tfeat[:, idx:idx+num_columns-i-1] = X[:, i+1:] * X[:, i][:, np.newaxis]\n","\t\tidx += num_columns - i - 1\n","\treturn feat"],"metadata":{"id":"XUZOr_uLiNt3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Z_trn = np.loadtxt( \"secret_train.dat\" )\n","Z_tst = np.loadtxt( \"secret_test.dat\" )\n","\n","n_trials = 5\n","\n","d_size = 0\n","t_train = 0\n","t_map = 0\n","acc = 0"],"metadata":{"id":"x0salcYbPVeY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for t in range( n_trials ):\n","\ttic = tm.perf_counter()\n","\tw, b = my_fit( Z_trn[:, :-1], Z_trn[:,-1] )\n","\ttoc = tm.perf_counter()\n","\tt_train += toc - tic\n","\n","\td_size += w.shape[0]\n","\n","\ttic = tm.perf_counter()\n","\tfeat = my_map( Z_tst[:, :-1] )\n","\ttoc = tm.perf_counter()\n","\tt_map += toc - tic\n","\n","\tscores = feat.dot( w ) + b\n","\tpred = np.zeros_like( scores )\n","\tpred[scores > 0] = 1\n","\tacc += np.average( Z_tst[ :, -1 ] == pred )"],"metadata":{"id":"hwn4Alu6Pz1u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d_size /= n_trials\n","t_train /= n_trials\n","t_map /= n_trials\n","acc /= n_trials\n","\n","print( d_size, t_train, t_map, 1- acc )"],"metadata":{"id":"ZVG4OM_PQ1EG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711821340379,"user_tz":-330,"elapsed":10,"user":{"displayName":"Lavesh Gupta","userId":"12842633363256377808"}},"outputId":"2edc0aca-8d9f-42bb-c105-f1bfc6cc97f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["528.0 1.720048247199884 0.07185956200046348 0.006900000000000128\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"PYy49i7rYOAW"},"execution_count":null,"outputs":[]}]}